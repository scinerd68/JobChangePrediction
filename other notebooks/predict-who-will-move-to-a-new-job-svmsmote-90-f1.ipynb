{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split as tts, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, f1_score, precision_score, roc_auc_score, roc_curve, auc\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.776</td>\n",
       "      <td>Male</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>15</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>Full time course</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Business Degree</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>never</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.767</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>Part time course</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>High School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.762</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>7</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>17</td>\n",
       "      <td>10000+</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>123</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_development_index gender      relevent_experience enrolled_university  \\\n",
       "0                   0.920   Male  Has relevent experience       no_enrollment   \n",
       "1                   0.776   Male   No relevent experience       no_enrollment   \n",
       "2                   0.624    NaN   No relevent experience    Full time course   \n",
       "3                   0.789    NaN   No relevent experience                 NaN   \n",
       "4                   0.767   Male  Has relevent experience       no_enrollment   \n",
       "5                   0.764    NaN  Has relevent experience    Part time course   \n",
       "6                   0.920   Male  Has relevent experience       no_enrollment   \n",
       "7                   0.762   Male  Has relevent experience       no_enrollment   \n",
       "8                   0.920   Male  Has relevent experience       no_enrollment   \n",
       "9                   0.920    NaN  Has relevent experience       no_enrollment   \n",
       "\n",
       "  education_level major_discipline experience company_size    company_type  \\\n",
       "0        Graduate             STEM        >20          NaN             NaN   \n",
       "1        Graduate             STEM         15        50-99         Pvt Ltd   \n",
       "2        Graduate             STEM          5          NaN             NaN   \n",
       "3        Graduate  Business Degree         <1          NaN         Pvt Ltd   \n",
       "4         Masters             STEM        >20        50-99  Funded Startup   \n",
       "5        Graduate             STEM         11          NaN             NaN   \n",
       "6     High School              NaN          5        50-99  Funded Startup   \n",
       "7        Graduate             STEM         13          <10         Pvt Ltd   \n",
       "8        Graduate             STEM          7        50-99         Pvt Ltd   \n",
       "9        Graduate             STEM         17       10000+         Pvt Ltd   \n",
       "\n",
       "  last_new_job  training_hours  target  \n",
       "0            1              36     1.0  \n",
       "1           >4              47     0.0  \n",
       "2        never              83     0.0  \n",
       "3        never              52     1.0  \n",
       "4            4               8     0.0  \n",
       "5            1              24     1.0  \n",
       "6            1              24     0.0  \n",
       "7           >4              18     1.0  \n",
       "8            1              46     1.0  \n",
       "9           >4             123     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = [\"n/a\", \"na\", \"--\", \"NONE\", \"None\", \"none\", \"NA\", \"N/A\",'inf','-inf', '?', 'Null', 'NULL']\n",
    "# train_data = pd.read_csv('aug_train.csv', na_values = missing_values)\n",
    "train_data = pd.read_csv('data/aug_train.csv')\n",
    "train_data.drop(['enrollee_id', 'city'], 1, inplace=True)\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19158, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19158 entries, 0 to 19157\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   city_development_index  19158 non-null  float64\n",
      " 1   gender                  14650 non-null  object \n",
      " 2   relevent_experience     19158 non-null  object \n",
      " 3   enrolled_university     18772 non-null  object \n",
      " 4   education_level         18698 non-null  object \n",
      " 5   major_discipline        16345 non-null  object \n",
      " 6   experience              19093 non-null  object \n",
      " 7   company_size            13220 non-null  object \n",
      " 8   company_type            13018 non-null  object \n",
      " 9   last_new_job            18735 non-null  object \n",
      " 10  training_hours          19158 non-null  int64  \n",
      " 11  target                  19158 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(9)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, there is some Human error in column company size i.e. Oct-49 and in pandas it was printed as 10/49, so we need to convert into np.nan(NaN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50-99        3083\n",
      "100-500      2571\n",
      "10000+       2019\n",
      "10/49        1471\n",
      "1000-4999    1328\n",
      "<10          1308\n",
      "500-999       877\n",
      "5000-9999     563\n",
      "Name: company_size, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print(train_data.company_size.value_counts())\n",
    "# train_data['company_size'] = train_data['company_size'].replace('10/49', np.nan)\n",
    "# print(\"==============================\")\n",
    "print(train_data.company_size.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just checking total unique values in every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'city_development_index' has '93' unique categories\n",
      "Feature 'gender' has '4' unique categories\n",
      "Feature 'relevent_experience' has '2' unique categories\n",
      "Feature 'enrolled_university' has '4' unique categories\n",
      "Feature 'education_level' has '6' unique categories\n",
      "Feature 'major_discipline' has '7' unique categories\n",
      "Feature 'experience' has '23' unique categories\n",
      "Feature 'company_size' has '9' unique categories\n",
      "Feature 'company_type' has '7' unique categories\n",
      "Feature 'last_new_job' has '7' unique categories\n",
      "Feature 'training_hours' has '241' unique categories\n",
      "Feature 'target' has '2' unique categories\n"
     ]
    }
   ],
   "source": [
    "for col_name in train_data.columns:\n",
    "  if (train_data[col_name].dtypes == 'int64' or train_data[col_name].dtypes == 'float64' or train_data[col_name].dtypes == 'object'):\n",
    "    unique_cat = len(train_data[col_name].unique())\n",
    "    print(\"Feature '{col_name}' has '{unique_cat}' unique categories\".format(col_name = col_name, unique_cat = unique_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city_development_index       0\n",
       "gender                    4508\n",
       "relevent_experience          0\n",
       "enrolled_university        386\n",
       "education_level            460\n",
       "major_discipline          2813\n",
       "experience                  65\n",
       "company_size              5938\n",
       "company_type              6140\n",
       "last_new_job               423\n",
       "training_hours               0\n",
       "target                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_LabelEncode = train_data[['gender', 'relevent_experience',\n",
    "       'enrolled_university', 'education_level', 'major_discipline',\n",
    "       'experience', 'company_size', 'company_type', 'last_new_job']]\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_temp = to_LabelEncode.astype(\"str\").apply(le.fit_transform)\n",
    "train_final = train_temp.where(~to_LabelEncode.isna(), to_LabelEncode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19153</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19155</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19156</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19157</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19158 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  relevent_experience enrolled_university education_level  \\\n",
       "0          1                    0                   3               0   \n",
       "1          1                    1                   3               0   \n",
       "2        NaN                    1                   0               0   \n",
       "3        NaN                    1                 NaN               0   \n",
       "4          1                    0                   3               2   \n",
       "...      ...                  ...                 ...             ...   \n",
       "19153      1                    1                   3               0   \n",
       "19154      1                    0                   3               0   \n",
       "19155      1                    0                   3               0   \n",
       "19156      1                    0                   3               1   \n",
       "19157    NaN                    1                   3               4   \n",
       "\n",
       "      major_discipline experience company_size company_type last_new_job  \n",
       "0                    5         21          NaN          NaN            0  \n",
       "1                    5          6            4            5            4  \n",
       "2                    5         15          NaN          NaN            6  \n",
       "3                    1         20          NaN            5            6  \n",
       "4                    5         21            4            1            3  \n",
       "...                ...        ...          ...          ...          ...  \n",
       "19153                2          5          NaN          NaN            0  \n",
       "19154                5          5          NaN          NaN            3  \n",
       "19155                5         21            4            5            3  \n",
       "19156              NaN         20            5            5            1  \n",
       "19157              NaN         11          NaN          NaN            0  \n",
       "\n",
       "[19158 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['gender', 'relevent_experience','enrolled_university', 'education_level', 'major_discipline','experience', 'company_size', 'company_type', 'last_new_job'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_final.join(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MICE (Multiple Imputation by Chained Equations) Imputation. Its a multiple imputation method, it is generally better than  single imputation method like mean imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\impute\\_iterative.py:685: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.008503</td>\n",
       "      <td>4.070495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.776</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.953038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.036662</td>\n",
       "      <td>4.713792</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.940145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.907067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.923227</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.767</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19153</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.019819</td>\n",
       "      <td>4.069892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.878</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.978869</td>\n",
       "      <td>4.394476</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19155</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19156</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.655379</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.802</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19157</th>\n",
       "      <td>0.921575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.605653</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.097360</td>\n",
       "      <td>4.065754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19158 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gender  relevent_experience  enrolled_university  education_level  \\\n",
       "0      1.000000                  0.0             3.000000              0.0   \n",
       "1      1.000000                  1.0             3.000000              0.0   \n",
       "2      0.953038                  1.0             0.000000              0.0   \n",
       "3      0.940145                  1.0             1.907067              0.0   \n",
       "4      1.000000                  0.0             3.000000              2.0   \n",
       "...         ...                  ...                  ...              ...   \n",
       "19153  1.000000                  1.0             3.000000              0.0   \n",
       "19154  1.000000                  0.0             3.000000              0.0   \n",
       "19155  1.000000                  0.0             3.000000              0.0   \n",
       "19156  1.000000                  0.0             3.000000              1.0   \n",
       "19157  0.921575                  1.0             3.000000              4.0   \n",
       "\n",
       "       major_discipline  experience  company_size  company_type  last_new_job  \\\n",
       "0              5.000000        21.0      3.008503      4.070495           0.0   \n",
       "1              5.000000         6.0      4.000000      5.000000           4.0   \n",
       "2              5.000000        15.0      3.036662      4.713792           6.0   \n",
       "3              1.000000        20.0      2.923227      5.000000           6.0   \n",
       "4              5.000000        21.0      4.000000      1.000000           3.0   \n",
       "...                 ...         ...           ...           ...           ...   \n",
       "19153          2.000000         5.0      3.019819      4.069892           0.0   \n",
       "19154          5.000000         5.0      2.978869      4.394476           3.0   \n",
       "19155          5.000000        21.0      4.000000      5.000000           3.0   \n",
       "19156          4.655379        20.0      5.000000      5.000000           1.0   \n",
       "19157          4.605653        11.0      3.097360      4.065754           0.0   \n",
       "\n",
       "       city_development_index  training_hours  target  \n",
       "0                       0.920            36.0     1.0  \n",
       "1                       0.776            47.0     0.0  \n",
       "2                       0.624            83.0     0.0  \n",
       "3                       0.789            52.0     1.0  \n",
       "4                       0.767             8.0     0.0  \n",
       "...                       ...             ...     ...  \n",
       "19153                   0.878            42.0     1.0  \n",
       "19154                   0.920            52.0     1.0  \n",
       "19155                   0.920            44.0     0.0  \n",
       "19156                   0.802            97.0     0.0  \n",
       "19157                   0.855           127.0     0.0  \n",
       "\n",
       "[19158 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "mice_imputer = IterativeImputer(random_state=42, estimator=lr, max_iter=10, n_nearest_features=2, imputation_order = 'roman')\n",
    "train_final_df = mice_imputer.fit_transform(train_data)\n",
    "\n",
    "train_final_df = pd.DataFrame(train_final_df)\n",
    "train_final_df.columns = ['gender', 'relevent_experience', 'enrolled_university', 'education_level', 'major_discipline',\n",
    "                                                         'experience', 'company_size', 'company_type', 'last_new_job', 'city_development_index', 'training_hours', 'target']\n",
    "                                                        \n",
    "train_final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we dont have any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = train_final_df.copy()\n",
    "# final_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heavy class imbalance is present in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    14381\n",
       "1.0     4777\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into X and y and than standardizing it using Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_train.drop('target',1)\n",
    "y = final_train.target\n",
    "\n",
    "X_train,X_test,y_train,y_test = tts(X,y,test_size=0.25, random_state=42)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applied SVMSmote, I also applied different variants of Smote like SMOTE, SMOTE-NC, KmeansSMOTE, AdasysMOTE, BorderlineSMOTE. KmeansSMOTE also gave me very good result but due some compatibility issue of kmeansSmote which uses sklearn version 0.20 only and MICE imputation required newer version of sklearn version, so I switched kmeans smote to SVMSmote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_smote = SVMSMOTE(sampling_strategy='minority', random_state=42, k_neighbors=5)\n",
    "X_svm_smote, y_svm_smote = svm_smote.fit_resample(X,y)\n",
    "\n",
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = tts(X_svm_smote,y_svm_smote, test_size=0.25, random_state=42)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_svm = sc.fit_transform(X_train_svm)\n",
    "X_test_svm = sc.transform(X_test_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    errors = abs(y_pred - y_test)\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print('Recall Score = ',recall_score(y_test, y_pred))\n",
    "    print('Precision Score = ',precision_score(y_test, y_pred))\n",
    "    print('F1 score = ', f1_score(y_test,y_pred))\n",
    "\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_auc_roc_curve(model, X_test, y_test, X_train, y_train):\n",
    "  base_fpr,base_tpr,base_threshold = roc_curve(y_train, model.predict(X_train))\n",
    "  plt.plot([0,1])\n",
    "  plt.plot(base_fpr,base_tpr)\n",
    "  print(\"auc score :\",auc(base_fpr,base_tpr))\n",
    "  \n",
    "\n",
    "  return train_auc_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applied EasyEnsembleClassifier of imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error: 0.0443 degrees.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.96     10778\n",
      "         1.0       0.97      0.94      0.95     10793\n",
      "\n",
      "    accuracy                           0.96     21571\n",
      "   macro avg       0.96      0.96      0.96     21571\n",
      "weighted avg       0.96      0.96      0.96     21571\n",
      "\n",
      "[[10499   279]\n",
      " [  677 10116]]\n",
      "Recall Score =  0.9372741591772445\n",
      "Precision Score =  0.9731601731601731\n",
      "F1 score =  0.9548801208231075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.evaluate(model, X_test, y_test)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy_lgbm = EasyEnsembleClassifier(base_estimator= LGBMClassifier(random_state=42), n_estimators=250, n_jobs=1,\n",
    "                       random_state=42, replacement=True,\n",
    "                       sampling_strategy='auto', verbose=0,\n",
    "                       warm_start=True)\n",
    "easy_lgbm.fit(X_train_svm, y_train_svm)\n",
    "evaluate(easy_lgbm, X_train_svm, y_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error: 0.0560 degrees.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.95      3603\n",
      "         1.0       0.96      0.92      0.94      3588\n",
      "\n",
      "    accuracy                           0.94      7191\n",
      "   macro avg       0.94      0.94      0.94      7191\n",
      "weighted avg       0.94      0.94      0.94      7191\n",
      "\n",
      "[[3472  131]\n",
      " [ 272 3316]]\n",
      "Recall Score =  0.9241917502787068\n",
      "Precision Score =  0.961995938497244\n",
      "F1 score =  0.9427149964463397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.evaluate(model, X_test, y_test)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(easy_lgbm, X_test_svm, y_test_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ON REAL DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error: 0.7485 degrees.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.01     10797\n",
      "         1.0       0.25      1.00      0.40      3571\n",
      "\n",
      "    accuracy                           0.25     14368\n",
      "   macro avg       0.62      0.50      0.20     14368\n",
      "weighted avg       0.81      0.25      0.11     14368\n",
      "\n",
      "[[   43 10754]\n",
      " [    0  3571]]\n",
      "Recall Score =  1.0\n",
      "Precision Score =  0.2492844677137871\n",
      "F1 score =  0.39908359409924005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.evaluate(model, X_test, y_test)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(easy_lgbm, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error: 0.7443 degrees.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.01      0.01      3584\n",
      "         1.0       0.25      1.00      0.40      1206\n",
      "\n",
      "    accuracy                           0.26      4790\n",
      "   macro avg       0.63      0.50      0.21      4790\n",
      "weighted avg       0.81      0.26      0.11      4790\n",
      "\n",
      "[[  19 3565]\n",
      " [   0 1206]]\n",
      "Recall Score =  1.0\n",
      "Precision Score =  0.2527771955564871\n",
      "F1 score =  0.4035469298979421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.evaluate(model, X_test, y_test)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(easy_lgbm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the f1 score of both train and test(validation) and printing the probablity of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39908359409924005\n",
      "0.4035469298979421\n"
     ]
    }
   ],
   "source": [
    "# print(f1_score(y_train_svm, easy_lgbm.predict(X_train_svm)))\n",
    "# print(f1_score(y_test_svm, easy_lgbm.predict(X_test_svm)))\n",
    "\n",
    "# predict_proba_easy_lgbm = pd.DataFrame(easy_lgbm.predict_proba(X_test_svm))\n",
    "# predict_proba_easy_lgbm\n",
    "\n",
    "print(f1_score(y_train, easy_lgbm.predict(X_train)))\n",
    "print(f1_score(y_test, easy_lgbm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used eli5 library to find out feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eli5_permutation = PermutationImportance(estimator = easy_lgbm, scoring = 'f1', random_state=42, n_iter = 5)\n",
    "# eli5_permutation.fit(X_test_svm, y_test_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eli5_permutation.feature_importances_.T.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the lowest and highest importance of every feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eli5.show_weights(eli5_permutation, feature_names = X.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_with_eli5=pd.DataFrame(np.hstack((np.array([X.columns[0:]]).T, eli5_permutation.feature_importances_.T.reshape(-1,1))), columns=['feature', 'importance'])\n",
    "# feature_importance_with_eli5['importance']=pd.to_numeric(feature_importance_with_eli5['importance'])\n",
    "# feature_importance_with_eli5.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender is most important factor to understand whether he or she will change the job or not, followed by City Development Index and Company Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (15,8))\n",
    "# plt.xticks(fontsize=15)\n",
    "# plt.yticks(fontsize=15)\n",
    "# # We sort by importance and get the features\n",
    "# sns.barplot(x = 'importance', y = 'feature', data = feature_importance_with_eli5, \n",
    "#             order = feature_importance_with_eli5.sort_values('importance', ascending=False).feature) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very good score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_auc_roc_curve(easy_lgbm, X_test_svm, y_test_svm, X_train_svm, y_train_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_values = [\"n/a\", \"na\", \"--\", \"NONE\", \"None\", \"none\", \"NA\", \"N/A\",'inf','-inf', '?', 'Null', 'NULL']\n",
    "# test_data = pd.read_csv('../input/hr-analytics-job-change-of-data-scientists/aug_test.csv', na_values= missing_values)\n",
    "# test_data.drop(['enrollee_id', 'city'], 1, inplace=True)\n",
    "# test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data['company_size'] = test_data['company_size'].replace('10/49', np.nan)\n",
    "# test_data['company_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_LabelEncode_test = test_data[['gender', 'relevent_experience',\n",
    "#        'enrolled_university', 'education_level', 'major_discipline',\n",
    "#        'experience', 'company_size', 'company_type', 'last_new_job']]\n",
    "\n",
    "# test_temp = to_LabelEncode_test.astype(\"str\").apply(le.fit_transform)\n",
    "# test_final = test_temp.where(~to_LabelEncode_test.isna(), to_LabelEncode_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.drop(['gender', 'relevent_experience','enrolled_university', 'education_level', 'major_discipline','experience', 'company_size', 'company_type', 'last_new_job'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = test_final.join(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_final_df = mice_imputer.fit_transform(test_data)\n",
    "\n",
    "# test_final_df = pd.DataFrame(test_final_df)\n",
    "# test_final_df.columns = ['gender', 'relevent_experience', 'enrolled_university', 'education_level', 'major_discipline',\n",
    "#                                                          'experience', 'company_size', 'company_type', 'last_new_job', 'city_development_index', 'training_hours']\n",
    "                                                        \n",
    "# test_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_final_df = sc.transform(test_final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = pd.DataFrame(easy_lgbm.predict(test_final_df))\n",
    "# prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 0.5\n",
    "# my_pred = np.where(prediction>threshold,'Will join the company','Will not join the company')\n",
    "\n",
    "# my_pred = my_pred.T.reshape(-1,1)\n",
    "# my_pred = pd.DataFrame(my_pred, columns=['Decision'])\n",
    "# my_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_pred = my_pred.join(pd.DataFrame(easy_lgbm.predict_proba(test_final_df)), lsuffix='_right', rsuffix='_left')\n",
    "# my_pred = my_pred.rename({0 : 'Probablity of not joining', 1 : 'Probablity of joining'}, axis=1)\n",
    "# my_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, the project is completed.\n",
    "\n",
    "What I have done:\n",
    "1. Loaded Libraries and train data\n",
    "2. Deleted the unwanted columns.\n",
    "3. Cleaned some Human Error\n",
    "4. Label Encoded the data\n",
    "5. Missing value Imputation via MICE technique\n",
    "6. Checked for Class Imbalance\n",
    "7. Splitted data into X and y, Standardized it.\n",
    "8. Applied SVMSmote and solved class imbalance issue.\n",
    "9. Applied Easy Ensemble Classifier Model with base estimator as Default LGBMClassifier of Imblearn package\n",
    "10. Checked the feature importance according to the model using eli5 library\n",
    "11. Finalized the Easy Ensemble Classifier model with base estimator as Default LGBMClassifier.\n",
    "12. Predicted on Test Data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
